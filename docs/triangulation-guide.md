# Triangulering & Objektdetektering - Teknisk Guide

## üìê Grundprincip - Triangulering

```
cameraPosition ‚Üí Object1 ‚Üí Object2
         ‚Üë          ‚Üë         ‚Üë
      Kameran   Boulen   Cochonnet
```

Triangulering anv√§nds f√∂r att ber√§kna verkliga avst√•nd mellan objekt i 3D-rymd baserat p√• 2D-bilder fr√•n kameran.

### Hur det fungerar

1. **Kameraposition** - K√§nd referenspunkt
2. **Objekt 1 (Boule)** - Detekterad position i bilden
3. **Objekt 2 (Cochonnet)** - Detekterad position i bilden
4. **Ber√§kning** - Anv√§nd geometri och kameramatris f√∂r att f√• verkligt avst√•nd

---

## üõ†Ô∏è Tekniker att anv√§nda

### 1. **ARKit** (iOS) / **ARCore** (Android)
- Ger direkt djupinformation fr√•n enheten
- B√§st f√∂r realtidsapplikationer
- Inbyggt st√∂d f√∂r plan-detektering
- H√∂g noggrannhet

**F√∂rdelar:**
- Native integration
- Automatisk kalibrering
- World tracking
- Ljusestimering

**Implementation:**
```javascript
// iOS - ARKit
import { ARView } from 'react-native-arkit';

// Android - ARCore
import { ARCoreView } from 'react-native-arcore';
```

### 2. **Stereo Vision** (med tv√• kameror)
- Anv√§nder tv√• kameror f√∂r djupber√§kning
- Simulerar m√§nskligt seende
- Kr√§ver kalibrering mellan kamerorna

**F√∂rdelar:**
- Passiv teknik (ingen projektion)
- Fungerar i olika ljusf√∂rh√•llanden
- Bra f√∂r utomhusbruk

**Nackdelar:**
- Kr√§ver tv√• kameror
- Mer komplex kalibrering
- Ber√§kningsintensivt

### 3. **LiDAR** (p√• nyare iPhone/iPad)
- Laser-baserad avst√•ndsm√§tning
- Extremt noggrann (¬±1cm)
- Fungerar i m√∂rker

**Enheter med LiDAR:**
- iPhone 12 Pro/Pro Max och senare
- iPhone 13 Pro/Pro Max
- iPhone 14 Pro/Pro Max
- iPhone 15 Pro/Pro Max
- iPad Pro (2020 och senare)

**Implementation:**
```javascript
import { useLiDAR } from 'react-native-lidar';

const depthData = useLiDAR();
```

---

## ü§ñ Machine Learning - Objektdetektering

### Python Implementation

```python
# Machine Learning-modell f√∂r att identifiera objekt
def detect_objects(image):
    """
    Detektera boular och cochonnet i bild
    
    Args:
        image: Input-bild (numpy array)
        
    Returns:
        tuple: (boules, cochonnet)
    """
    # 1. Bildf√∂rbehandling
    processed_image = preprocess(image)
    
    # 2. Objektdetektering med ML-modell
    objects = ml_model.detect(processed_image)
    
    # 3. Filtrera boular vs cochonnet
    boules = filter_boules(objects)
    cochonnet = find_cochonnet(objects)
    
    return boules, cochonnet


def preprocess(image):
    """
    F√∂rbehandla bild f√∂r b√§ttre detektering
    """
    # Resize till modellens input-storlek
    resized = cv2.resize(image, (640, 640))
    
    # Normalisera pixelv√§rden
    normalized = resized.astype('float32') / 255.0
    
    # F√∂rb√§ttra kontrast
    lab = cv2.cvtColor(normalized, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    enhanced = cv2.merge([l, a, b])
    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
    
    return enhanced


def filter_boules(objects):
    """
    Filtrera ut boular fr√•n detekterade objekt
    """
    boules = []
    
    for obj in objects:
        # Kontrollera storlek (boular √§r ~75mm diameter)
        if 60 < obj['diameter'] < 90:
            # Kontrollera form (cirkul√§r)
            if obj['circularity'] > 0.8:
                # Kontrollera f√§rg (metallisk/silver)
                if is_metallic_color(obj['color']):
                    boules.append(obj)
    
    return boules


def find_cochonnet(objects):
    """
    Hitta cochonnet (liten r√∂d boll)
    """
    for obj in objects:
        # Cochonnet √§r mindre (~30mm diameter)
        if 20 < obj['diameter'] < 40:
            # Kontrollera f√§rg (r√∂d/orange)
            if is_red_color(obj['color']):
                return obj
    
    return None
```

---

## üì± React Native Implementation

### Camera Service med Frame Processor

```javascript
// cameraService.js
import { Camera } from 'react-native-vision-camera';
import { useFrameProcessor } from 'react-native-vision-camera';
import { runOnJS } from 'react-native-reanimated';

/**
 * Frame processor f√∂r realtidsanalys
 * K√∂rs p√• varje bildruta fr√•n kameran
 */
const frameProcessor = useFrameProcessor((frame) => {
  'worklet';
  
  // Analysera varje bildruta i realtid
  const objects = detectBoules(frame);
  const distances = calculateDistances(objects);
  
  // Uppdatera UI med resultat
  runOnJS(updateUI)(distances);
}, []);


/**
 * Detektera boular i frame
 */
function detectBoules(frame) {
  'worklet';
  
  // Konvertera frame till format som ML-modellen f√∂rst√•r
  const imageData = frameToImageData(frame);
  
  // K√∂r objektdetektering
  const detections = runMLModel(imageData);
  
  return {
    boules: detections.boules,
    cochonnet: detections.cochonnet,
    timestamp: Date.now(),
  };
}


/**
 * Ber√§kna avst√•nd mellan objekt
 */
function calculateDistances(objects) {
  'worklet';
  
  const { boules, cochonnet } = objects;
  
  if (!cochonnet || boules.length === 0) {
    return [];
  }
  
  const distances = boules.map((boule) => {
    // Triangulering f√∂r att f√• verkligt avst√•nd
    const distance = triangulate(
      cochonnet.position,
      boule.position,
      getCameraParameters()
    );
    
    return {
      bouleId: boule.id,
      distance: distance,
      unit: 'meters',
    };
  });
  
  // Sortera efter avst√•nd (n√§rmast f√∂rst)
  return distances.sort((a, b) => a.distance - b.distance);
}


/**
 * Triangulering f√∂r avst√•ndsber√§kning
 */
function triangulate(point1, point2, cameraParams) {
  'worklet';
  
  // Ber√§kna pixelavst√•nd
  const dx = point2.x - point1.x;
  const dy = point2.y - point1.y;
  const pixelDistance = Math.sqrt(dx * dx + dy * dy);
  
  // Konvertera till verkligt avst√•nd
  const focalLength = cameraParams.focalLength;
  const sensorSize = cameraParams.sensorSize;
  const imageSize = cameraParams.imageSize;
  
  // Formel: realDistance = (pixelDistance √ó sensorSize √ó distance) / (focalLength √ó imageSize)
  const estimatedDistance = (focalLength * sensorSize) / imageSize;
  const realDistance = (pixelDistance * estimatedDistance) / focalLength;
  
  return realDistance;
}


/**
 * Uppdatera UI med detektionsresultat
 */
function updateUI(distances) {
  // Denna funktion k√∂rs p√• JS-tr√•den (inte worklet)
  console.log('Detected distances:', distances);
  
  // Uppdatera state eller skicka event
  EventEmitter.emit('distancesUpdated', distances);
}
```

---

## üéØ Komplett Exempel - Camera Component

```javascript
import React, { useState, useCallback } from 'react';
import { View, Text, StyleSheet } from 'react-native';
import { Camera, useFrameProcessor } from 'react-native-vision-camera';
import { runOnJS } from 'react-native-reanimated';

const BouleCamera = () => {
  const [distances, setDistances] = useState([]);
  const [detectedObjects, setDetectedObjects] = useState({ boules: [], cochonnet: null });

  // Callback f√∂r att uppdatera UI fr√•n worklet
  const updateDetections = useCallback((objects, calculatedDistances) => {
    setDetectedObjects(objects);
    setDistances(calculatedDistances);
  }, []);

  // Frame processor
  const frameProcessor = useFrameProcessor((frame) => {
    'worklet';
    
    try {
      // 1. Detektera objekt
      const objects = detectBoules(frame);
      
      // 2. Ber√§kna avst√•nd
      const distances = calculateDistances(objects);
      
      // 3. Uppdatera UI
      runOnJS(updateDetections)(objects, distances);
    } catch (error) {
      console.error('Frame processing error:', error);
    }
  }, [updateDetections]);

  return (
    <View style={styles.container}>
      <Camera
        style={StyleSheet.absoluteFill}
        device={device}
        isActive={true}
        frameProcessor={frameProcessor}
      />
      
      {/* Overlay med detektionsinfo */}
      <View style={styles.overlay}>
        <Text style={styles.title}>Detekterade objekt</Text>
        
        {/* Boular */}
        <Text style={styles.subtitle}>
          Boular: {detectedObjects.boules.length}
        </Text>
        
        {/* Avst√•nd */}
        {distances.map((d, index) => (
          <Text key={index} style={styles.distance}>
            Boule {d.bouleId}: {d.distance.toFixed(2)}m
          </Text>
        ))}
        
        {/* Cochonnet */}
        {detectedObjects.cochonnet && (
          <Text style={styles.cochonnet}>
            ‚úì Cochonnet detekterad
          </Text>
        )}
      </View>
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
  },
  overlay: {
    position: 'absolute',
    top: 20,
    left: 20,
    backgroundColor: 'rgba(0, 0, 0, 0.7)',
    padding: 16,
    borderRadius: 8,
  },
  title: {
    color: '#fff',
    fontSize: 18,
    fontWeight: 'bold',
    marginBottom: 8,
  },
  subtitle: {
    color: '#fff',
    fontSize: 14,
    marginBottom: 4,
  },
  distance: {
    color: '#4CAF50',
    fontSize: 12,
    marginLeft: 8,
  },
  cochonnet: {
    color: '#FF6B6B',
    fontSize: 14,
    marginTop: 8,
  },
});

export default BouleCamera;
```

---

## üìä Noggrannhet & Optimering

### F√∂rb√§ttra noggrannhet

1. **Kamerakalibrering**
   - M√§t kamerans intrinsiska parametrar
   - Korrigera f√∂r lins-distorsion
   - Anv√§nd checkerboard-pattern f√∂r kalibrering

2. **Referensobjekt**
   - Anv√§nd k√§nd storlek (cochonnet = 30mm)
   - Kalibrerar automatiskt f√∂r avst√•nd

3. **Flera m√§tningar**
   - Medelv√§rde √∂ver flera frames
   - Filtrera bort outliers
   - Kalman-filter f√∂r smooth tracking

4. **Ljusf√∂rh√•llanden**
   - Anpassa f√∂r olika ljus
   - HDR-st√∂d
   - Skuggkompensation

### Performance-optimering

```javascript
// K√∂r inte varje frame
let frameCount = 0;
const PROCESS_EVERY_N_FRAMES = 3;

const frameProcessor = useFrameProcessor((frame) => {
  'worklet';
  
  frameCount++;
  if (frameCount % PROCESS_EVERY_N_FRAMES !== 0) {
    return; // Skippa denna frame
  }
  
  // Process frame...
}, []);
```

---

## üî¨ Testning & Validering

### Test med k√§nda avst√•nd

```javascript
// Placera objekt p√• k√§nda avst√•nd och verifiera
const testDistances = [
  { actual: 0.5, measured: 0.48, error: 0.02 },
  { actual: 1.0, measured: 0.97, error: 0.03 },
  { actual: 2.0, measured: 2.05, error: 0.05 },
];

const averageError = testDistances.reduce((sum, t) => sum + t.error, 0) / testDistances.length;
console.log(`Average error: ${averageError.toFixed(3)}m`);
```

---

## üìö Resurser

- [ARKit Documentation](https://developer.apple.com/augmented-reality/)
- [ARCore Documentation](https://developers.google.com/ar)
- [React Native Vision Camera](https://react-native-vision-camera.com/)
- [OpenCV Triangulation](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html)
- [TensorFlow Object Detection](https://www.tensorflow.org/lite/examples/object_detection/overview)
